# CLIAå‘½ä»¤è¡Œå·¥å…·å®ç°æ–¹æ¡ˆ

## ğŸ¯ ç›®æ ‡

è®©CLIAèƒ½å¤Ÿç›´æ¥åœ¨terminalä¸­è¿è¡Œï¼š
```bash
clia -q "äº”è‰²èŠ±æœµè¯¥æ€ä¹ˆåŸ¹è‚²ï¼Ÿ" -t general
```

## ğŸ“‹ å®ç°æ­¥éª¤

### 1. åˆ›å»ºåŒ…å®‰è£…é…ç½®

#### setup.py æ–‡ä»¶
```python
"""
CLIA - An Efficient Minimalist CLI AI Agent
"""

from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

with open("requirements.txt", "r", encoding="utf-8") as fh:
    requirements = [line.strip() for line in fh if line.strip() and not line.startswith("#")]

setup(
    name="clia",
    version="0.1.0",
    author="Your Name",
    author_email="your.email@example.com",
    description="An Efficient Minimalist CLI AI Agent",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/your-repo/clia",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
        "Topic :: Software Development :: Libraries :: Python Modules",
    ],
    python_requires=">=3.8",
    install_requires=requirements,
    entry_points={
        "console_scripts": [
            "clia=clia.main:main",
        ],
    },
    include_package_data=True,
    package_data={
        "clia": ["*.json", "*.yaml", "*.yml"],
    },
)
```

### 2. é‡æ„é¡¹ç›®ç»“æ„

#### æ–°çš„ç›®å½•ç»“æ„
```
clia/
â”œâ”€â”€ setup.py                    # åŒ…å®‰è£…é…ç½®
â”œâ”€â”€ requirements.txt             # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                  # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ .env.example              # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ clia/                    # ä¸»åŒ…ç›®å½•
â”‚   â”œâ”€â”€ __init__.py          # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ main.py              # å‘½ä»¤è¡Œå…¥å£
â”‚   â”œâ”€â”€ config.py           # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ utils.py            # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ logger.py           # æ—¥å¿—ç®¡ç†
â”‚   â””â”€â”€ agents/            # Agentæ¨¡å—
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm.py         # LLMå®¢æˆ·ç«¯
â”‚       â”œâ”€â”€ prompts.py     # Promptç®¡ç†
â”‚       â””â”€â”€ history.py     # å†å²è®°å½•
â””â”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
    â””â”€â”€ test_clia.py
```

### 3. åˆ›å»ºåŒ…åˆå§‹åŒ–æ–‡ä»¶

#### clia/__init__.py
```python
"""
CLIA - An Efficient Minimalist CLI AI Agent

A simple, efficient CLI tool for AI assistance with multiple task types.
"""

__version__ = "0.1.0"
__author__ = "Your Name"
__email__ = "your.email@example.com"

from .main import main
from .config import Settings

__all__ = ["main", "Settings", "__version__"]
```

### 4. åˆ›å»ºå‘½ä»¤è¡Œå…¥å£

#### clia/main.py
```python
#!/usr/bin/env python3
"""
CLIA Main Entry Point

This module provides the main entry point for the CLI command.
"""

import argparse
import sys
from pathlib import Path

from .config import Settings
from .agents import llm, prompts
from .agents.history import History
from .utils import to_bool
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_parser() -> argparse.ArgumentParser:
    """Create and configure the argument parser."""
    parser = argparse.ArgumentParser(
        prog="clia",
        description="An Efficient Minimalist CLI AI Agent",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  clia -q "Hello, how are you?" -t general
  clia -q "Explain this Python code" -t explain
  clia -q "Generate a sorting algorithm" -t generate
  clia -q "Debug this error" -t debug
  clia -q "Fix this bug" -t fix
        """
    )
    
    # ä¸»è¦å‚æ•°
    parser.add_argument(
        'question', 
        nargs='+',
        help='Question to ask the AI Agent'
    )
    
    parser.add_argument(
        '-t', '--task',
        choices=['general', 'explain', 'generate', 'debug', 'fix'],
        default='general',
        help='Task type to perform (default: general)'
    )
    
    parser.add_argument(
        '-f', '--format',
        choices=['markdown', 'json', 'text'],
        default='markdown',
        help='Output format (default: markdown)'
    )
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        '--model',
        help='Model to override the default'
    )
    
    parser.add_argument(
        '--temperature',
        type=float,
        help='Temperature to override the default'
    )
    
    parser.add_argument(
        '--top_p',
        type=float,
        help='Top P to override the default'
    )
    
    parser.add_argument(
        '--max_retries',
        type=int,
        help='Max retries to override the default'
    )
    
    # è¾“å‡ºæ§åˆ¶
    parser.add_argument(
        '--stream',
        action='store_true',
        help='Enable streaming output'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Enable verbose output'
    )
    
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='Suppress non-essential output'
    )
    
    # å†å²è®°å½•
    parser.add_argument(
        '--history',
        help='Path to save conversation history'
    )
    
    parser.add_argument(
        '--no-history',
        action='store_true',
        help='Disable history saving'
    )
    
    return parser


def main():
    """Main entry point for the CLI application."""
    try:
        parser = create_parser()
        args = parser.parse_args()
        
        # å¤„ç†é—®é¢˜å‚æ•°
        if isinstance(args.question, list):
            args.question = ' '.join(args.question)
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        elif args.quiet:
            logging.getLogger().setLevel(logging.WARNING)
        
        # å¦‚æœä¸æ˜¯quietæ¨¡å¼ï¼Œæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
        if not args.quiet:
            print('-' * 28)
            print("Welcome to CLI AI Agent")
            print('-' * 28 + '\n')
        
        logger.info(f"User Query: {args.question}")
        logger.info(f"Task: {args.task}")
        
        # åŠ è½½é…ç½®
        settings = Settings.load_openai()
        logger.info(f"Settings loaded: model={settings.model}")
        
        # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        model = args.model or settings.model
        stream = args.stream or settings.stream
        temperature = args.temperature or settings.temperature
        top_p = args.top_p or settings.top_p
        max_retries = args.max_retries or settings.max_retries
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        client = llm.openai_client(
            api_key=settings.api_key,
            base_url=settings.base_url,
            max_retries=max_retries
        )
        
        # è·å–ä»»åŠ¡ç‰¹å®šçš„prompt
        system_prompt, few_shots = prompts.get_prompt(args.task)
        messages = [
            {"role": "system", "content": system_prompt},
            *few_shots,
            {"role": "user", "content": args.question}
        ]
        
        logger.info(f"Messages prepared for {args.task} task")
        
        # è°ƒç”¨LLM API
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            stream=stream,
            temperature=temperature,
            top_p=top_p,
            frequency_penalty=settings.frequency_penalty,
            max_tokens=settings.max_tokens,
            timeout=settings.timeout_seconds
        )
        
        # å¤„ç†å“åº”
        full_response = []
        
        if not stream:
            # éæµå¼è¾“å‡º
            content = response.choices[0].message.content
            full_response.append(content)
            print(content)
        else:
            # æµå¼è¾“å‡º
            if not args.quiet:
                print('-' * 28 + '\n')
            
            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    full_response.append(content)
            
            if not args.quiet:
                print('\n' + '-' * 28 + '\n')
        
        # ä¿å­˜å†å²è®°å½•
        if not args.no_history and args.history:
            history = History([
                {"role": "user", "content": args.question},
                {"role": "assistant", "content": ''.join(full_response)}
            ])
            history.save_jsonl(Path(args.history))
            logger.info(f"History saved to {args.history}")
        
        logger.info("Request completed successfully")
        
    except KeyboardInterrupt:
        print("\n\nOperation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Error: {e}")
        if not args.quiet:
            print(f"\nError: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

### 5. æ›´æ–°ç°æœ‰æ¨¡å—

#### æ›´æ–° config.py
```python
import os
import sys
from pathlib import Path
from dataclasses import dataclass
from dotenv import load_dotenv
from .utils import to_bool

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ç¡®ä¿åŒ…æ ¹ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
package_root = Path(__file__).parent.parent
if str(package_root) not in sys.path:
    sys.path.insert(0, str(package_root))


@dataclass
class Settings:
    """Configuration settings for CLIA."""
    
    api_key: str
    base_url: str
    model: str
    temperature: float
    stream: bool
    max_tokens: int
    timeout_seconds: int
    max_retries: int
    top_p: float
    frequency_penalty: float

    @classmethod
    def load_openai(cls):
        """Load OpenAI settings from environment variables."""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError('OPENAI_API_KEY not set in environment variables')
        
        return cls(
            api_key=api_key,
            base_url=os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1'),
            model=os.getenv('OPENAI_MODEL', 'glm-4.6'),
            stream=to_bool(os.getenv('OPENAI_STREAM', 'False')),
            temperature=float(os.getenv('OPENAI_TEMPERATURE', '0.0')),
            max_tokens=int(os.getenv('OPENAI_MAX_TOKENS', '4096')),
            max_retries=int(os.getenv('OPENAI_MAX_RETRIES', '5')),
            timeout_seconds=int(os.getenv('OPENAI_TIMEOUT_SECONDS', '30')),
            top_p=float(os.getenv('OPENAI_TOP_P', '0.85')),
            frequency_penalty=float(os.getenv('OPENAI_FREQUENCY_PENALTY', '0'))
        )
```

#### æ›´æ–° agents/__init__.py
```python
"""
CLIA Agents Module

This module provides the core agent functionality including LLM integration,
prompt management, and conversation history.
"""

from .llm import openai_client
from .prompts import get_prompt
from .history import History

__all__ = ["openai_client", "get_prompt", "History"]
```

## ğŸš€ å®‰è£…å’Œä½¿ç”¨æ­¥éª¤

### 1. å¼€å‘ç¯å¢ƒå®‰è£…
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
cd å¤§æ¨¡å‹/clia

# å®‰è£…ä¸ºå¯ç¼–è¾‘åŒ…
pip install -e .

# æˆ–è€…ä½¿ç”¨å¼€å‘æ¨¡å¼å®‰è£…
python setup.py develop
```

### 2. ç”Ÿäº§ç¯å¢ƒå®‰è£…
```bash
# ä»GitHubå®‰è£…
pip install git+https://github.com/your-repo/clia.git

# æˆ–è€…ä»PyPIå®‰è£…ï¼ˆå¦‚æœå‘å¸ƒåˆ°PyPIï¼‰
pip install clia
```

### 3. é…ç½®ç¯å¢ƒå˜é‡
```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ç¯å¢ƒå˜é‡
# OPENAI_API_KEY=your_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=glm-4.6
```

### 4. ä½¿ç”¨å‘½ä»¤
```bash
# åŸºç¡€ç”¨æ³•
clia "äº”è‰²èŠ±æœµè¯¥æ€ä¹ˆåŸ¹è‚²ï¼Ÿ" -t general

# æŒ‡å®šä»»åŠ¡ç±»å‹
clia "è§£é‡Šä¸€ä¸‹Pythonè£…é¥°å™¨" -t explain

# ä»£ç ç”Ÿæˆ
clia "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•" -t generate

# å¯ç”¨æµå¼è¾“å‡º
clia "ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ " --stream

# ä¿å­˜å†å²è®°å½•
clia "å¸®æˆ‘è°ƒè¯•è¿™æ®µä»£ç " -t debug --history conversation.jsonl

# è¯¦ç»†è¾“å‡º
clia "ç”Ÿæˆä¸€ä¸ªWebæœåŠ¡å™¨" -t generate --verbose

# é™é»˜æ¨¡å¼
clia "ä¿®å¤è¿™ä¸ªbug" -t fix --quiet
```

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
```bash
# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
export CLIA_CONFIG_PATH=/path/to/config.yaml
clia "ä½ çš„é—®é¢˜"
```

### å¤šæ¨¡å‹æ”¯æŒ
```bash
# ä½¿ç”¨ä¸åŒæ¨¡å‹
clia "ä½ çš„é—®é¢˜" --model=gpt-4
clia "ä½ çš„é—®é¢˜" --model=claude-3-sonnet
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å‘½ä»¤æœªæ‰¾åˆ°**
   ```bash
   # ç¡®ä¿å·²æ­£ç¡®å®‰è£…
   pip install -e .
   
   # æ£€æŸ¥PATH
   echo $PATH | grep python
   ```

2. **APIå¯†é’¥é”™è¯¯**
   ```bash
   # æ£€æŸ¥ç¯å¢ƒå˜é‡
   echo $OPENAI_API_KEY
   
   # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
   source ~/.bashrc  # æˆ– ~/.zshrc
   ```

3. **æ¨¡å—å¯¼å…¥é”™è¯¯**
   ```bash
   # é‡æ–°å®‰è£…åŒ…
   pip uninstall clia
   pip install -e .
   ```

## ğŸ“‹ æµ‹è¯•

### å•å…ƒæµ‹è¯•
```bash
# è¿è¡Œæµ‹è¯•
python -m pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m pytest tests/test_clia.py::test_main
```

### é›†æˆæµ‹è¯•
```bash
# æµ‹è¯•å‘½ä»¤è¡Œæ¥å£
clia "æµ‹è¯•é—®é¢˜" -t general --verbose

# æµ‹è¯•æ‰€æœ‰ä»»åŠ¡ç±»å‹
for task in general explain generate debug fix; do
    echo "Testing $task task..."
    clia "æµ‹è¯• $task ä»»åŠ¡" -t $task
done
```

## ğŸ“¦ å‘å¸ƒå‡†å¤‡

### æ„å»ºåŒ…
```bash
# æ„å»ºæºç åŒ…å’ŒwheelåŒ…
python setup.py sdist bdist_wheel

# æ£€æŸ¥åŒ…
twine check dist/*
```

### å‘å¸ƒåˆ°PyPI
```bash
# ä¸Šä¼ åˆ°æµ‹è¯•PyPI
twine upload --repository testpypi dist/*

# ä¸Šä¼ åˆ°æ­£å¼PyPI
twine upload dist/*
```

---

è¿™ä¸ªå®ç°æ–¹æ¡ˆå°†è®©ä½ çš„CLIAæˆä¸ºä¸€ä¸ªçœŸæ­£çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥åœ¨terminalä¸­ä½¿ç”¨ `clia` å‘½ä»¤ã€‚